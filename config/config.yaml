# Use existing conda environments (must be the same names) or create new ones just for this pipeline?
conda_envs:
  use_existing_envs: true
  envs_path: '~/work/miniconda/envs/' # path to conda envs if use_existing_envs is true

data:
  samples_in_directory: false # boolean, are samples or their symlinks in resource/data?
  # if previous is false, give path to sample sheet
  sample_sheet_path: 'resources/sample_sheet.tsv' # tab-separated columns: sample_name|path

# Count matrix/layer to use for analysis downstream of normalization
count_layer: ['soupX_counts', 'counts'] # usually 'soupX_counts' or 'counts'

# quality control method to use
# 'theislab_tutorial', 'theislab_tutorial_then_scAutoQC' or 'scAutoQC' (which failed miserably in my case)
# only choose one of the methods including scAutoQC
qc_method: ['theislab_tutorial', 'scAutoQC']

subset:
  use: False # perform analysis after merging of samples on subset (true) or full (false) dataset?
  fraction: 0.2 # fraction of cells to use for subset analysis

# different methods for dimensionality reduction of the merged data
dim_reduc:
  normalization: 'log1p_norm'
  scale_data_before_pca: [True, False] # scale data before PCA?
  genes_for_pca: ['all', 'globally_highly_variable', 'highly_variable_per_sample'] # which genes to use for PCA
  cc_method: ['None', 'regress_out', 'cc_genes_out', 'cc_difference_regressed_out', 'cPCA'] # method to remove cell cycle effect
  pca_n_components: 50 # number of components to use for PCA
  umap_n_neighbors: 30 # number of neighbors to use for UMAP

chosen_branch: 'results/merged/dim_reduc_potential_cc_removal/count_layer__counts/normalization__log1p_norm/scale_data_before_pca__False/genes_for_pca__highly_variable_per_sample/cc_method__cc_genes_out/pca_n_components__50/umap_n_neighbors__30/qc_method__theislab_tutorial'

chosen_clustering: 'results/chosen_branch/leiden_res0.4.csv'